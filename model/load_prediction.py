# -*- coding: utf-8 -*-
"""Untitled29.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZsMdxJEgyNQGussdFpxJPdSf2H37Hvtm
"""

!pip install catboost

# -*- coding: utf-8 -*-
"""
Improved Loan Eligibility Prediction Pipeline
Goal: Achieve 83–87% test accuracy (realistic target for this dataset)
"""

# =============================================
# 1. Import Libraries
# =============================================
import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

from imblearn.over_sampling import SMOTE

# Stronger models
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier

import warnings
warnings.filterwarnings('ignore')

# =============================================
# 2. Load & Basic Cleaning
# =============================================
df = pd.read_csv("/content/train_u6lujuX_CVtuZ9i (1).csv")   # ← adjust path if needed

# Drop useless ID
df = df.drop(columns=['Loan_ID'], errors='ignore')

# =============================================
# 3. Feature Engineering (before splitting)
# =============================================
def create_features(df):
    # Total income (very strong signal)
    df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']

    # Avoid division by zero
    df['Loan_Amount_Term'] = df['Loan_Amount_Term'].replace(0, np.nan)

    # EMI approximation (strong predictor)
    df['EMI'] = df['LoanAmount'] / df['Loan_Amount_Term']   # monthly approx

    # Income to loan ratio
    df['Income_to_Loan'] = df['Total_Income'] / (df['LoanAmount'] + 1)  # +1 to avoid div0

    # Loan amount per person (rough)
    df['Dependents'] = df['Dependents'].replace('3+', '3').astype(float)
    df['Loan_per_person'] = df['LoanAmount'] / (df['Dependents'] + 1)

    return df

df = create_features(df)

# =============================================
# 4. Train / Val / Test Split (RAW data)
# =============================================
X = df.drop(columns=['Loan_Status'])
y = df['Loan_Status'].map({'Y': 1, 'N': 0})

X_train, X_temp, y_train, y_temp = train_test_split(
    X, y, test_size=0.25, stratify=y, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42
)

print(f"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}")

# =============================================
# 5. Handle Missing Values
# =============================================
def fill_missing_values(df_train, df_val, df_test):
    # Numerical
    num_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',
                'Loan_Amount_Term', 'Total_Income', 'EMI',
                'Income_to_Loan', 'Loan_per_person']
    for col in num_cols:
        mean_val = df_train[col].mean()
        df_train[col] = df_train[col].fillna(mean_val)
        df_val[col]   = df_val[col].fillna(mean_val)
        df_test[col]  = df_test[col].fillna(mean_val)

    # Categorical
    cat_cols = ['Gender', 'Married', 'Dependents', 'Education',
                'Self_Employed', 'Property_Area', 'Credit_History']
    for col in cat_cols:
        mode_val = df_train[col].mode()[0]
        df_train[col] = df_train[col].fillna(mode_val)
        df_val[col]   = df_val[col].fillna(mode_val)
        df_test[col]  = df_test[col].fillna(mode_val)

    return df_train, df_val, df_test

X_train, X_val, X_test = fill_missing_values(X_train, X_val, X_test)

# =============================================
# 6. Encoding
# =============================================
def encode_features(df):
    # Ordinal-like → numeric
    df['Dependents'] = df['Dependents'].replace({'0':0, '1':1, '2':2, '3':3})

    # One-hot
    cat_cols = ['Gender', 'Married', 'Education', 'Self_Employed', 'Property_Area']
    df = pd.get_dummies(df, columns=cat_cols, drop_first=True, dtype=int)

    # Credit_History → int
    df['Credit_History'] = df['Credit_History'].astype(int)

    return df

X_train = encode_features(X_train)
X_val   = encode_features(X_val)
X_test  = encode_features(X_test)

# =============================================
# 7. SMOTE (only on train)
# =============================================
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

print("Class distribution after SMOTE:", pd.Series(y_train_res).value_counts().to_dict())

# =============================================
# 8. Scaling (optional – trees usually don't need it)
# =============================================
# scaler = StandardScaler()
# X_train_scaled = scaler.fit_transform(X_train_res)
# X_val_scaled   = scaler.transform(X_val)
# X_test_scaled  = scaler.transform(X_test)

# For tree models → usually better WITHOUT scaling
X_train_final = X_train_res      # or X_train_scaled
X_val_final   = X_val
X_test_final  = X_test

# =============================================
# 9. Modeling & Evaluation
# =============================================
models = {
    "RandomForest": RandomForestClassifier(
        n_estimators=500, max_depth=9, min_samples_leaf=3, random_state=42
    ),
    "HistGB": HistGradientBoostingClassifier(
        max_iter=400, max_depth=6, learning_rate=0.08, random_state=42
    ),
    "XGBoost": XGBClassifier(
        n_estimators=400, max_depth=4, learning_rate=0.07,
        subsample=0.85, colsample_bytree=0.8, random_state=42,
        eval_metric='logloss'
    ),
    "LightGBM": LGBMClassifier(
        n_estimators=300, max_depth=6, learning_rate=0.07,
        subsample=0.85, colsample_bytree=0.8, random_state=42,
        verbose=-1
    ),
    "CatBoost": CatBoostClassifier(
        iterations=400, depth=6, learning_rate=0.07,
        subsample=0.85, colsample_bylevel=0.8, random_state=42,
        verbose=0
    )
}

results = {}

for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train_final, y_train_res)

    # Predict
    pred_val  = model.predict(X_val_final)
    pred_test = model.predict(X_test_final)

    acc_val  = accuracy_score(y_val, pred_val)
    acc_test = accuracy_score(y_test, pred_test)

    results[name] = {"val": acc_val, "test": acc_test}

    print(f"{name:12}  Val acc: {acc_val:.4f}   Test acc: {acc_test:.4f}")

# Show best model
best_model_name = max(results, key=lambda k: results[k]['test'])
print(f"\nBest model: {best_model_name} → Test accuracy: {results[best_model_name]['test']:.4f}")

# Optional: detailed report of best model
best_model = models[best_model_name]
print("\nClassification Report (Test set):")
print(classification_report(y_test, best_model.predict(X_test_final)))

# =============================================
# 9. Modeling & Evaluation + Confusion Matrix (Best Model Only)
# =============================================
models = {
    "RandomForest": RandomForestClassifier(
        n_estimators=500, max_depth=9, min_samples_leaf=3, random_state=42
    ),
    "HistGB": HistGradientBoostingClassifier(
        max_iter=400, max_depth=6, learning_rate=0.08, random_state=42
    ),
    "XGBoost": XGBClassifier(
        n_estimators=400, max_depth=4, learning_rate=0.07,
        subsample=0.85, colsample_bytree=0.8, random_state=42,
        eval_metric='logloss'
    ),
    "LightGBM": LGBMClassifier(
        n_estimators=300, max_depth=6, learning_rate=0.07,
        subsample=0.85, colsample_bytree=0.8, random_state=42,
        verbose=-1
    ),
    # "CatBoost": ... (add back if you installed it)
}

results = {}

print("\n" + "="*60)
print("Model Training & Evaluation")
print("="*60)

for name, model in models.items():
    print(f"\n→ Training {name}...")
    model.fit(X_train_final, y_train_res)

    # Predictions
    y_pred_val  = model.predict(X_val_final)
    y_pred_test = model.predict(X_test_final)

    # Accuracies
    acc_val  = accuracy_score(y_val, y_pred_val)
    acc_test = accuracy_score(y_test, y_pred_test)

    # Store with consistent key names
    results[name] = {
        "val_acc": acc_val,
        "test_acc": acc_test,
        "model": model,                # save model reference
        "y_pred_test": y_pred_test     # save predictions for best model
    }

    print(f"   Val acc  : {acc_val:.4f}")
    print(f"   Test acc : {acc_test:.4f}")

# Find best model (using consistent key)
best_model_name = max(results, key=lambda k: results[k]['test_acc'])
best_result = results[best_model_name]
best_model = best_result["model"]
y_pred_best = best_result["y_pred_test"]

print("\n" + "="*60)
print(f"BEST MODEL: {best_model_name}")
print(f"Test Accuracy: {best_result['test_acc']:.4f}")
print("="*60)

# Classification Report
print("\nClassification Report (Test set):")
print(classification_report(y_test, y_pred_best, target_names=["Rejected (0)", "Approved (1)"]))

# Confusion Matrix - Visual
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred_best)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                             display_labels=["Rejected", "Approved"])
disp.plot(cmap=plt.cm.Blues, values_format='d')
plt.title(f"Confusion Matrix - {best_model_name} (Test Set)\nAccuracy: {best_result['test_acc']:.4f}")
plt.tight_layout()
plt.show()

# Optional: also show text version
print("\nConfusion Matrix (numbers):")
print("                   Predicted")
print("             Rejected    Approved")
print(f"Actual Rejected   {cm[0,0]:^8}     {cm[0,1]:^8}")
print(f"Actual Approved   {cm[1,0]:^8}     {cm[1,1]:^8}")



import joblib

# Get the best model from the previous execution
best_model_name = max(results, key=lambda k: results[k]['test_acc'])
best_model = results[best_model_name]['model']

# Define a filename for the saved model
model_filename = f'{best_model_name.lower()}_model.joblib'

# Save the model to a file
joblib.dump(best_model, model_filename)

print(f"Best model ('{best_model_name}') saved to {model_filename}")

